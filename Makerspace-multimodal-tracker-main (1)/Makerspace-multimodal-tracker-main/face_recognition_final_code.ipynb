{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy import stats\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Go to the README file of https://github.com/ageitgey/face_recognition to set up the ```face_recognition``` library locally, along with associated dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Filepaths & Place in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe with viable filepaths and the associated name of subject\n",
    "\n",
    "# get filepaths for for training and test datasets – test dataset contains one image per subject, training set\n",
    "# contains remaining images\n",
    "\n",
    "rootdir = '/Users/lanzhang/Face-Recognition-Demo/makerspace'\n",
    "\n",
    "paths = []\n",
    "names = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if subdir != rootdir and file != '.DS_Store':\n",
    "            filepath = str(os.path.join(subdir, file))\n",
    "            paths.append(filepath)\n",
    "            name = subdir.split(\"makerspace/\")[1]\n",
    "            names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas dataframe containing the filepath of each image and their associated subject name\n",
    "dataframe_dict = {}\n",
    "dataframe_dict['names'] = names\n",
    "dataframe_dict['filepath'] = paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df = pd.DataFrame.from_dict(dataframe_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tyler</td>\n",
       "      <td>/Users/lanzhang/Face-Recognition-Demo/makerspa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tyler</td>\n",
       "      <td>/Users/lanzhang/Face-Recognition-Demo/makerspa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tyler</td>\n",
       "      <td>/Users/lanzhang/Face-Recognition-Demo/makerspa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tyler</td>\n",
       "      <td>/Users/lanzhang/Face-Recognition-Demo/makerspa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tyler</td>\n",
       "      <td>/Users/lanzhang/Face-Recognition-Demo/makerspa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>alison</td>\n",
       "      <td>/Users/lanzhang/Face-Recognition-Demo/makerspa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>alison</td>\n",
       "      <td>/Users/lanzhang/Face-Recognition-Demo/makerspa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>alison</td>\n",
       "      <td>/Users/lanzhang/Face-Recognition-Demo/makerspa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4552</th>\n",
       "      <td>alison</td>\n",
       "      <td>/Users/lanzhang/Face-Recognition-Demo/makerspa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>alison</td>\n",
       "      <td>/Users/lanzhang/Face-Recognition-Demo/makerspa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4554 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       names                                           filepath\n",
       "0      tyler  /Users/lanzhang/Face-Recognition-Demo/makerspa...\n",
       "1      tyler  /Users/lanzhang/Face-Recognition-Demo/makerspa...\n",
       "2      tyler  /Users/lanzhang/Face-Recognition-Demo/makerspa...\n",
       "3      tyler  /Users/lanzhang/Face-Recognition-Demo/makerspa...\n",
       "4      tyler  /Users/lanzhang/Face-Recognition-Demo/makerspa...\n",
       "...      ...                                                ...\n",
       "4549  alison  /Users/lanzhang/Face-Recognition-Demo/makerspa...\n",
       "4550  alison  /Users/lanzhang/Face-Recognition-Demo/makerspa...\n",
       "4551  alison  /Users/lanzhang/Face-Recognition-Demo/makerspa...\n",
       "4552  alison  /Users/lanzhang/Face-Recognition-Demo/makerspa...\n",
       "4553  alison  /Users/lanzhang/Face-Recognition-Demo/makerspa...\n",
       "\n",
       "[4554 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned encoding for 4176 images.\n",
      "\n",
      "Execution time:  1213.9975180625916\n"
     ]
    }
   ],
   "source": [
    "# list containing encodings for training faces\n",
    "known_face_encodings = []\n",
    "\n",
    "# list containing labels for training faces\n",
    "known_face_names = []\n",
    "\n",
    "not_recognized = []\n",
    "\n",
    "# iterate through each training image, learn encoding, append true label to known_face_names\n",
    "train_paths = all_data_df['filepath'].tolist()\n",
    "train_names = all_data_df['names'].tolist()\n",
    "\n",
    "start = time.time()\n",
    "for image_num in range(len(train_paths)):\n",
    "    image = face_recognition.load_image_file(train_paths[image_num])\n",
    "    boxes = face_recognition.face_locations(image, model=\"cnn\")\n",
    "    try:\n",
    "        face_encoding = face_recognition.face_encodings(image, boxes)[0]\n",
    "        known_face_encodings.append(face_encoding)\n",
    "        known_face_names.append(train_names[image_num])\n",
    "    except:\n",
    "        not_recognized.append(image_num)\n",
    "end = time.time()\n",
    "\n",
    "print('Learned encoding for', len(known_face_encodings), 'images.')\n",
    "print('\\nExecution time: ', (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe with viable filepaths and the associated name of subject\n",
    "\n",
    "# get filepaths for for training and test datasets – test dataset contains one image per subject, training set\n",
    "# contains remaining images\n",
    "\n",
    "rootdir = '/Users/lanzhang/Face-Recognition-Demo/kinectaa_v2'\n",
    "\n",
    "kinectaa_paths = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if file != '.DS_Store':\n",
    "            filepath = str(os.path.join(subdir, file))\n",
    "            kinectaa_paths.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/Users/lanzhang/Face-Recognition-Demo/kinectbb_v2'\n",
    "\n",
    "kinectbb_paths = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if file != '.DS_Store':\n",
    "            filepath = str(os.path.join(subdir, file))\n",
    "            kinectbb_paths.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/Users/lanzhang/Face-Recognition-Demo/kinectcc_v2'\n",
    "\n",
    "kinectcc_paths = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if file != '.DS_Store':\n",
    "            filepath = str(os.path.join(subdir, file))\n",
    "            kinectcc_paths.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_filepaths = kinectbb_paths + kinectcc_paths\n",
    "video_filepaths = kinectaa_paths + kinectbb_paths + kinectcc_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_filepaths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_names = ['bertrand']*len(video_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy on Video Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_distance_to_conf(face_distance, face_match_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Converts Euclidean distance between two faces (one known, one unknown) into a percentage match score\n",
    "    (from: https://github.com/ageitgey/face_recognition/wiki/Calculating-Accuracy-as-a-Percentage)\n",
    "    \"\"\"\n",
    "    if face_distance > face_match_threshold:\n",
    "        range = (1.0 - face_match_threshold)\n",
    "        linear_val = (1.0 - face_distance) / (range * 2.0)\n",
    "        return linear_val\n",
    "    else:\n",
    "        range = face_match_threshold\n",
    "        linear_val = 1.0 - (face_distance / (range * 2.0))\n",
    "        return linear_val + ((1.0 - linear_val) * math.pow((linear_val - 0.5) * 2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  129.76945209503174\n"
     ]
    }
   ],
   "source": [
    "# list containing predicted names for test faces\n",
    "predicted = []\n",
    "\n",
    "# list containing true labels for test faces\n",
    "true_labels = []\n",
    "\n",
    "# list containing all images that a face was detected in, for prediction\n",
    "used_filepaths = []\n",
    "\n",
    "# list containing prediction confidence scores for each prediction, calculated from Euclidean distance\n",
    "distances = []\n",
    "\n",
    "# iterate through each image in test set and generate predictions\n",
    "start = time.time()\n",
    "for test_image_num in range(len(video_filepaths)):\n",
    "    unknown_image = face_recognition.load_image_file(video_filepaths[test_image_num])\n",
    "    face_locations = face_recognition.face_locations(unknown_image, model=\"cnn\")\n",
    "    face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
    "    \n",
    "    try:\n",
    "        face_encoding = face_encodings[0]\n",
    "\n",
    "        # See if the face is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # Or instead, use the known face with the smallest distance to the new face\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        \n",
    "        # \n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "            used_filepaths.append(video_filepaths[test_image_num])\n",
    "            distances.append(face_distance_to_conf(np.min(face_distances)))\n",
    "        \n",
    "        # update predictions and true labels listts\n",
    "        predicted.append(name)\n",
    "        true_labels.append(true_names[test_image_num])\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "end = time.time()\n",
    "print('Elapsed time: ', (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.3946360153256705\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = 1 - (sum(np.array(predicted) != np.array(true_labels))/(len(np.array(predicted))))\n",
    "print(\"Test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure with Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of immediately taking the mode across all predicted labels, here each prediction is assigned \n",
    "# a “vote” score (weight) equal to their associated confidence percentage before tallying up the total votes \n",
    "# for each label across all images\n",
    "\n",
    "# Final prediction is the label with the highest vote score\n",
    "\n",
    "all_labels = {}\n",
    "for label_index in range(len(predicted)):\n",
    "    label = predicted[label_index]\n",
    "    if label in all_labels.keys():\n",
    "        all_labels[label] += distances[label_index]\n",
    "    else:\n",
    "        all_labels[label] = distances[label_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bertrand': 95.8172609586571,\n",
       " 'adeeb': 37.44709657713603,\n",
       " 'vivek': 42.187764967072404,\n",
       " 'marc': 15.907130526140094,\n",
       " 'iulian': 15.906371831362364,\n",
       " 'mohamed': 3.718317324016341,\n",
       " 'plum': 2.8094665219441293,\n",
       " 'tajesh': 2.7623799739921306,\n",
       " 'emily': 2.784336167297263,\n",
       " 'hannes': 0.9146692371135874,\n",
       " 'prasanth': 2.741634372755758,\n",
       " 'khisai': 2.8276429812632173,\n",
       " 'peri': 0.943942762616834,\n",
       " 'jazib': 4.645471061525951,\n",
       " 'suki': 4.673962702151087,\n",
       " 'juliet': 2.7816133048279754,\n",
       " 'emily_tf': 3.6740690606346247,\n",
       " 'mitch': 0.9331013719750714}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bertrand\n"
     ]
    }
   ],
   "source": [
    "final_prediction = max(all_labels.items(), key=operator.itemgetter(1))[0]\n",
    "print(final_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
