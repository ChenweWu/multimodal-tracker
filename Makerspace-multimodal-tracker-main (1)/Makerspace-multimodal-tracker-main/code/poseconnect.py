import shleximport subprocessimport argparseimport pandas as pdimport jsonimport osimport globimport datetimeimport numpy as np# function to execute command in shelldef run_command(command):    process = subprocess.Popen(shlex.split(command), stdout=subprocess.PIPE)    while True:        output = process.stdout.readline()        if process.poll() is not None:            break        if output:            print(output.strip())    rc = process.poll()    return rc# function to create directoriesdef create_dir(target_dir):    if not os.path.exists(target_dir):        try:            os.makedirs(target_dir)        except:            pass        # function to round milliseconds in timestampsdef round_timestamp(dt_str,fps=30,round_ms=3):      def get_str(dt_subobject):        out = str(dt_subobject)        if len(out) == 1:            out = '0' + out        return out    def get_micro_str(dt_subobject):        out = str(int(round(dt_subobject/(10**6),round_ms)*(10**6)))        no_zeros = 6 - len(out)        out = no_zeros*'0' + out        return out    def get_round_anchors(fps):        time_base = round(1/fps,round_ms+2)        round_anchors = []        for i in range(fps):            round_anchors.append(round(i*time_base,round_ms))        round_anchors.append(1.0)        return np.array(round_anchors)    def get_nearest_ms(round_anchors,target_ms):        return int(round_anchors[np.argmin(np.abs(round_anchors - target_ms/(10**6)))]*(10**6))        dt_object = datetime.datetime.strptime(dt_str, "%Y-%m-%dT%H:%M:%S.%f+00:00")    round_anchors = get_round_anchors(fps)        year = get_str(dt_object.year)    month = get_str(dt_object.month)    day = get_str(dt_object.day)    hour = get_str(dt_object.hour)    minute = get_str(dt_object.minute)    second = get_str(dt_object.second)    microsecond = get_micro_str(get_nearest_ms(round_anchors,dt_object.microsecond))        if microsecond == '1000000':              microsecond = get_micro_str(0)        new_dt_str = "{}-{}-{}T{}:{}:{}.{}+00:00".format(year,month,day,hour,minute,second,microsecond)        new_dt_object = datetime.datetime.strptime(new_dt_str, "%Y-%m-%dT%H:%M:%S.%f+00:00") + datetime.timedelta(seconds=1)                year = get_str(new_dt_object.year)        month = get_str(new_dt_object.month)        day = get_str(new_dt_object.day)        hour = get_str(new_dt_object.hour)        minute = get_str(new_dt_object.minute)        second = get_str(new_dt_object.second)        microsecond = get_micro_str(get_nearest_ms(round_anchors,new_dt_object.microsecond))          timestamp_str = '{}-{}-{}T{}:{}:{}.{}+00:00'.format(year,month,day,hour,minute,second,microsecond)        return timestamp_str    # create function to create necessary json filedef df_to_json(df,json_out):        list_of_dicts = []    dict_keys = list(df.columns)        for i, row in df.iterrows():        single_dict = {}        for key in dict_keys:            single_dict[key] = row[key]                    list_of_dicts.append(single_dict)    with open(json_out, 'w') as f:        f.write(json.dumps(list_of_dicts))# function to combine pose_2d files from various webcams into onedef poseconnect_prep(poseconnect_time_folder,camera_calibration_csv,drop_duplicate_ts=False):        csv_files = glob.glob(poseconnect_time_folder+'*.csv')    df_pose2d = pd.DataFrame()          for csv_file in csv_files:        df_temp = pd.read_csv(csv_file)        ts_record = []        for i, row in df_temp.iterrows():            round_ts = round_timestamp(row['timestamp'])            if round_ts in ts_record:                if drop_duplicate_ts:                    df_temp.at[i,'timestamp'] = 'duplicate'                else:                    df_temp.at[i,'timestamp'] = round_ts            else:                df_temp.at[i,'timestamp'] = round_ts                ts_record.append(round_ts)        df_temp = df_temp[df_temp['timestamp']!='duplicate']        df_pose2d = df_pose2d.append(df_temp,ignore_index=True)          # write to json file    pose2d_path = output_dir+'df_pose_2d.json'    df_to_json(df_pose2d,pose2d_path)          # prep cameara calibration    df_camera_calibration = pd.read_csv(camera_calibration_csv)          # write to json file    camera_calibration_path = output_dir+'camera_calibration_info.json'    df_to_json(df_camera_calibration,camera_calibration_path)          return pose2d_path, camera_calibration_path# function for poseconnet reconstructiondef poseconnect_reconstruct(pose2d_path,camera_calibration_path,pose_threshold=2):            # reconstruct    pose_3d_path = output_dir + 'poses_3d.json'        command_line = 'poseconnect reconstruct \                    {} \                    {} \                    {} \                    --pose-model-name COCO-17 \                    --room-x-limits -2.0 10.0 \                    --room-y-limits -2.0 15.0 \                    --pose-3d-graph-initial-edge-threshold {}'.format(pose2d_path,camera_calibration_path,pose_3d_path,pose_threshold)        # execute in command line    run_command(command_line)        return pose_3d_pathdef poseconnect_tracks(pose_3d_path):        # add tracks    pose_3d_tracks_path = output_dir + 'poses_3d_with_tracks.json'        command_line_tracks = 'poseconnect track \                            {} \                            {}'.format(pose_3d_path,pose_3d_tracks_path)           # execute in command line    run_command(command_line_tracks)        return pose_3d_tracks_pathdef poseconnect_interpolate(pose_3d_tracks_path):        # interpolate    poses_3d_interpolated_path = output_dir + 'poses_3d_interpolated.json'        command_line_interpolate = 'poseconnect interpolate \                                {} \                                {}'.format(pose_3d_tracks_path,poses_3d_interpolated_path)        # execute in command line    run_command(command_line_interpolate)        return poses_3d_interpolated_pathdef convert_3Djson_to_df(jsonfile_3d):    df_results_3d = pd.DataFrame(columns=['pose_3d_id','pose_track_3d_id','timestamp','pose_2d_ids','keypoint_coordinates_3d'])        with open(jsonfile_3d) as json_data:      data = json.load(json_data)            for row in data:            df_results_3d = df_results_3d.append({'pose_3d_id' : row['pose_3d_id'],                                                'pose_track_3d_id': row['pose_track_3d_id'],                                                'timestamp': row['timestamp'],                                                'pose_2d_ids': row['pose_2d_ids'],                                                'keypoint_coordinates_3d' : row['keypoint_coordinates_3d']},ignore_index=True)             # save df_results_3d    df_results_3d.to_csv(output_dir+'df_results_3d.csv',index=0)    """----------------------------- options -----------------------------"""parser = argparse.ArgumentParser(description='Poseconnect')parser.add_argument('--camera_calibration', type=str, default='../info/camera_calibration_info.csv',                    help='path of camera calibration info csv')parser.add_argument('--poseconnect_cloud_dir', type=str,                    help='location of poseconnect cloud drive')parser.add_argument('--pose_threshold', type=str, default=2,                    help='pose threshold for poseconnect, use 2 for default, use 1 to relax criteria')args = parser.parse_args()if __name__ == "__main__":        # create necessary variables    code_dir = os.getcwd() +'/'    os.chdir(args.poseconnect_cloud_dir)    poseconnect_cloud_dir = os.getcwd() +'/'    os.chdir(code_dir)        # create necessary folders    output_dir = poseconnect_cloud_dir + 'poseconnect_results/'    create_dir(output_dir)        pose2d_path, camera_calibration_path = poseconnect_prep(poseconnect_cloud_dir,args.camera_calibration)    pose_3d_path = poseconnect_reconstruct(pose2d_path,camera_calibration_path,pose_threshold=args.pose_threshold)    #pose_3d_tracks_path = poseconnect_tracks(pose_3d_path)    #poses_3d_interpolated_path = poseconnect_interpolate(pose_3d_tracks_path)    #convert_3Djson_to_df(poses_3d_interpolated_path)